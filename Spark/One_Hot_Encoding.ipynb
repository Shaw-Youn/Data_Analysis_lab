{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0586f10",
   "metadata": {},
   "source": [
    "In PySpark, the process of converting categorical values into numeric values for machine learning typically involves two steps:\n",
    "\n",
    "1. **StringIndexer**: This converts string labels (categorical data) into numeric indices.\n",
    "2. **OneHotEncoder**: After using `StringIndexer`, you can apply `OneHotEncoder` to encode the indices as binary vectors (one-hot encoding).\n",
    "\n",
    "Here's a detailed step-by-step example of how to use `StringIndexer` and `OneHotEncoder` in PySpark:\n",
    "\n",
    "### 1. Setup and DataFrame Creation\n",
    "\n",
    "Let's create a simple PySpark DataFrame with a categorical column:\n",
    "\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"OneHotEncodingExample\").getOrCreate()\n",
    "\n",
    "# Sample Data\n",
    "data = [(\"Dog\",), (\"Cat\",), (\"Fish\",), (\"Dog\",), (\"Fish\",)]\n",
    "df = spark.createDataFrame(data, [\"animal\"])\n",
    "\n",
    "df.show()\n",
    "```\n",
    "\n",
    "### Output:\n",
    "\n",
    "```\n",
    "+------+\n",
    "|animal|\n",
    "+------+\n",
    "|   Dog|\n",
    "|   Cat|\n",
    "|  Fish|\n",
    "|   Dog|\n",
    "|  Fish|\n",
    "+------+\n",
    "```\n",
    "\n",
    "### 2. Applying `StringIndexer`\n",
    "\n",
    "The `StringIndexer` converts the categorical values (`\"Dog\"`, `\"Cat\"`, `\"Fish\"`) into numeric indices:\n",
    "\n",
    "```python\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Initialize the StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"animal\", outputCol=\"animal_index\")\n",
    "\n",
    "# Fit and transform the data\n",
    "df_indexed = indexer.fit(df).transform(df)\n",
    "\n",
    "df_indexed.show()\n",
    "```\n",
    "\n",
    "### Output after `StringIndexer`:\n",
    "\n",
    "```\n",
    "+------ +------------+\n",
    "|animal |animal_index|\n",
    "+-------+------------+\n",
    "|   Dog |        0.0 |\n",
    "|   Cat |        2.0 |\n",
    "|  Fish |        1.0 |\n",
    "|   Dog |        0.0 |\n",
    "|  Fish |        1.0 |\n",
    "+-------+------------+\n",
    "```\n",
    "\n",
    "### Explanation of `StringIndexer`:\n",
    "- It assigns numeric indices to each categorical value.\n",
    "- In this case, `\"Dog\"` is assigned `0.0`, `\"Fish\"` is `1.0`, and `\"Cat\"` is `2.0`.\n",
    "\n",
    "### 3. Applying `OneHotEncoder`\n",
    "\n",
    "After converting the categorical values into indices, the next step is to use `OneHotEncoder` to convert these indices into binary vectors.\n",
    "\n",
    "```python\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(inputCol=\"animal_index\", outputCol=\"animal_ohe\")\n",
    "\n",
    "# Fit and transform the data\n",
    "df_encoded = encoder.fit(df_indexed).transform(df_indexed)\n",
    "\n",
    "df_encoded.show(truncate=False)\n",
    "```\n",
    "\n",
    "### Output after `OneHotEncoder`:\n",
    "\n",
    "```\n",
    "+------+------------+-------------+\n",
    "|animal|animal_index|animal_ohe    |\n",
    "+------+------------+-------------+\n",
    "|Dog   |0.0         |(2,[0],[1.0])|\n",
    "|Cat   |2.0         |(2,[],[])    |\n",
    "|Fish  |1.0         |(2,[1],[1.0])|\n",
    "|Dog   |0.0         |(2,[0],[1.0])|\n",
    "|Fish  |1.0         |(2,[1],[1.0])|\n",
    "+------+------------+-------------+\n",
    "```\n",
    "\n",
    "### Explanation of `OneHotEncoder`:\n",
    "- The `animal_index` is converted into a sparse vector `animal_ohe`.\n",
    "- `(2,[0],[1.0])` means a vector of size 2, with a `1.0` in the first position (`[0]` index).\n",
    "- `(2,[1],[1.0])` means a vector of size 2, with a `1.0` in the second position (`[1]` index).\n",
    "- The vector size depends on the highest index in the `animal_index` column. Since `\"Cat\"` has an index of `2.0` (and is not represented by a `1.0` in the one-hot encoding), it has an empty vector.\n",
    "\n",
    "### 4. Relationship Between `StringIndexer` and `OneHotEncoder`:\n",
    "- **StringIndexer**: Converts categorical string values into numeric indices. This is necessary because many machine learning algorithms do not work with strings but with numerical values.\n",
    "- **OneHotEncoder**: Converts these numeric indices into one-hot encoded vectors, which are often used in machine learning algorithms to represent categorical data without implying any ordinal relationship between categories.\n",
    "\n",
    "### Final DataFrame after both steps:\n",
    "\n",
    "- **`animal`**: Original categorical column.\n",
    "- **`animal_index`**: Indexed numeric values from `StringIndexer`.\n",
    "- **`animal_ohe`**: One-hot encoded sparse vectors from `OneHotEncoder`.\n",
    "\n",
    "This approach is especially useful when working with machine learning models that need categorical data in numerical form but without an ordinal implication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58deddfc",
   "metadata": {},
   "source": [
    " Here's a clearer breakdown of how `StringIndexer` and `OneHotEncoder` work together:\n",
    "\n",
    "1. **`StringIndexer`**: This is a pre-processing step that converts categorical string values (like `\"Dog\"`, `\"Cat\"`, `\"Fish\"`) into **numeric indices** (such as `0.0`, `1.0`, `2.0`). These numeric indices are essentially an intermediary step. **It does not encode the categorical values into a form suitable for machine learning models yet**, as these indices imply an ordinal relationship (which may not be meaningful for categories).\n",
    "\n",
    "2. **`OneHotEncoder`**: After you get numeric indices from `StringIndexer`, you use `OneHotEncoder` to convert these indices into **one-hot encoded vectors**. One-hot encoding converts each category into a vector where only one element is `1` and the rest are `0`. This removes the ordinal nature that was introduced by the index, thus making the data more appropriate for models where no order between categories is assumed (like in decision trees, linear models, etc.).\n",
    "\n",
    "### How They Work Together:\n",
    "\n",
    "- **`StringIndexer`**: Maps each categorical value to a unique index (integer).\n",
    "- **`OneHotEncoder`**: Converts these numeric indices into a **one-hot vector**, which is the actual representation used in most machine learning models to ensure categories are treated as separate entities without order.\n",
    "\n",
    "### Example:\n",
    "- **Before `StringIndexer`**: You have categories like `Dog`, `Cat`, `Fish`.\n",
    "- **After `StringIndexer`**: These categories are converted to indices like `0.0`, `1.0`, `2.0`.\n",
    "- **After `OneHotEncoder`**: These indices are then one-hot encoded to something like `(2,[0],[1.0])`, `(2,[1],[1.0])`, etc., which is a binary vector representation.\n",
    "\n",
    "### Key Point:\n",
    "- **StringIndexer** is just the **first step** in the process. It’s essential but not sufficient for one-hot encoding.\n",
    "- **OneHotEncoder** is applied **after `StringIndexer`** to give the final numeric (one-hot) encoding suitable for machine learning models.\n",
    "\n",
    "So, `StringIndexer` is a pre-step, and **the actual numeric transformation happens through `OneHotEncoder`**. This is why they often work together when converting categorical values into numerical form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb0448",
   "metadata": {},
   "source": [
    "The primary difference between `get_dummies()` in Pandas and the combination of `StringIndexer` and `OneHotEncoder` in PySpark lies in how they are implemented, their intended use cases, and their handling of the transformation process. Let’s break down these differences:\n",
    "\n",
    "### 1. **Library and Context**\n",
    "   - **`get_dummies()`**: This is a Pandas function and is primarily used in small- to medium-sized datasets within Python. It directly converts categorical values into one-hot encoded columns.\n",
    "   - **`StringIndexer` and `OneHotEncoder`**: These are PySpark machine learning transformers, designed for distributed processing across large datasets using Spark's distributed architecture. They are part of the PySpark MLlib library and operate within the Spark environment.\n",
    "\n",
    "### 2. **Workflow**\n",
    "\n",
    "   - **`get_dummies()`**:\n",
    "     - Directly converts a categorical column into multiple one-hot encoded columns without the need for intermediate steps.\n",
    "     - It’s a single-step process, meaning you don't need to apply a separate indexer or encoder.\n",
    "     - Example:\n",
    "       ```python\n",
    "       pd.get_dummies(df['animal'], prefix='animal')\n",
    "       ```\n",
    "       This produces one-hot encoded columns immediately.\n",
    "\n",
    "   - **`StringIndexer` and `OneHotEncoder`**:\n",
    "     - Two-step process:\n",
    "       1. **`StringIndexer`**: Converts the categorical values into numeric indices.\n",
    "       2. **`OneHotEncoder`**: Converts the numeric indices from `StringIndexer` into one-hot encoded vectors.\n",
    "     - This approach allows more control, especially for machine learning pipelines, because you may want to index categories before encoding them, or use indexed categories directly for certain types of models (e.g., decision trees or gradient-boosting algorithms).\n",
    "\n",
    "### 3. **Output Format**\n",
    "   - **`get_dummies()`**:\n",
    "     - Creates a **new column** for each category with `0` or `1` as values, where `1` indicates the presence of that category in a row and `0` indicates absence.\n",
    "     - Example:\n",
    "       ```plaintext\n",
    "       animal_Dog  animal_Cat  animal_Fish\n",
    "       1           0           0\n",
    "       0           1           0\n",
    "       0           0           1\n",
    "       ```\n",
    "     - The result is a DataFrame with as many new columns as there are unique categories in the original column.\n",
    "     \n",
    "   - **`OneHotEncoder`**:\n",
    "     - Produces a **sparse vector** representing the one-hot encoded values in a single column, especially for large datasets where many categories might lead to sparse matrices.\n",
    "     - Example:\n",
    "       ```plaintext\n",
    "       (2, [0], [1.0])  # Vector of size 2 with a 1 at position 0\n",
    "       (2, [1], [1.0])  # Vector of size 2 with a 1 at position 1\n",
    "       ```\n",
    "     - This method is more efficient in terms of memory and performance for large datasets.\n",
    "\n",
    "### 4. **Scalability**\n",
    "   - **`get_dummies()`**:\n",
    "     - Best suited for small- to medium-sized datasets handled within memory. It can become inefficient for large datasets because it creates a dense matrix of one-hot encoded columns, which can consume a lot of memory.\n",
    "   - **`StringIndexer` and `OneHotEncoder`**:\n",
    "     - Designed for use in PySpark's distributed processing framework, making them scalable for very large datasets across clusters. The use of sparse vectors by `OneHotEncoder` is more memory efficient in large-scale data processing.\n",
    "\n",
    "### 5. **Handling of New Categories**\n",
    "   - **`get_dummies()`**:\n",
    "     - It can handle all the categories present in the original DataFrame but might have issues if you apply it to new categories (e.g., during inference or test time) that were not seen during training.\n",
    "     - You have to manually ensure that the new data has the same categorical structure as the training data.\n",
    "     \n",
    "   - **`StringIndexer` and `OneHotEncoder`**:\n",
    "     - In PySpark, you can specify how to handle unseen categories when creating pipelines. For example, `StringIndexer` has a parameter called `handleInvalid` that can specify how to deal with invalid or unseen categories (e.g., set them to a specific index or skip them).\n",
    "     - This makes it easier to apply to new data in production environments.\n",
    "\n",
    "### 6. **Use Case for Machine Learning**\n",
    "   - **`get_dummies()`**:\n",
    "     - Commonly used for quick exploratory data analysis and simpler machine learning tasks in Pandas. It can be sufficient for many models (e.g., logistic regression, neural networks) that accept dense matrices.\n",
    "   - **`StringIndexer` and `OneHotEncoder`**:\n",
    "     - Specifically designed for use in Spark ML pipelines, where you might need to combine multiple transformers and estimators for large-scale machine learning tasks. It provides more flexibility and is better integrated into the machine learning pipeline framework in PySpark.\n",
    "\n",
    "### Summary Table:\n",
    "\n",
    "| Feature                   | `get_dummies()` (Pandas)                                      | `StringIndexer` + `OneHotEncoder` (PySpark)                   |\n",
    "|----------------------------|---------------------------------------------------------------|----------------------------------------------------------------|\n",
    "| Library                    | Pandas                                                        | PySpark MLlib                                                  |\n",
    "| Steps                      | Single-step: direct one-hot encoding                          | Two-step: index with `StringIndexer`, encode with `OneHotEncoder` |\n",
    "| Output                     | New columns for each category (dense matrix)                  | Single column with sparse vectors                              |\n",
    "| Use Case                   | Small to medium datasets, in-memory operations                | Large-scale datasets, distributed processing                   |\n",
    "| Memory Efficiency          | Less efficient (dense matrix for each category)               | More efficient (sparse vectors)                                |\n",
    "| Handling of New Categories  | Not easily handled                                           | Can handle unseen categories (e.g., `handleInvalid` in `StringIndexer`) |\n",
    "| Machine Learning Pipelines  | Limited integration                                           | Fully integrated into Spark ML pipelines                       |\n",
    "| Scalability                | Not suitable for very large datasets                          | Suitable for large datasets in distributed environments        |\n",
    "\n",
    "### Conclusion:\n",
    "- Use **get_dummies()** in Pandas for smaller datasets and when you don't need distributed processing.\n",
    "- Use **StringIndexer** and **OneHotEncoder** in PySpark for larger datasets or when building scalable machine learning pipelines, especially when you need efficient memory management with sparse vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474c23c",
   "metadata": {},
   "source": [
    "### **Remark**: \n",
    "In PySpark, the `StringIndexer` class by default does not handle unseen (new) categorical values that may appear in test data but were not present in the training data. If a new category is encountered, PySpark raises an error. However, you can configure it to handle unseen labels by setting the `handleInvalid` parameter.\n",
    "\n",
    "Here are the options for the `handleInvalid` parameter:\n",
    "\n",
    "1. **\"error\"** (default): Throws an error when encountering new labels.\n",
    "2. **\"skip\"**: Removes rows with new labels.\n",
    "3. **\"keep\"**: Assigns an index to all new labels (usually the index `0`).\n",
    "\n",
    "To handle new categorical values gracefully, you can set `handleInvalid=\"keep\"` when creating the `StringIndexer`. This will map any unseen categories to a specific index, ensuring your model can process new data without errors.\n",
    "\n",
    "### Example:\n",
    "```python\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Sample dataset\n",
    "data = spark.createDataFrame([(\"a\",), (\"b\",), (\"c\",)], [\"category\"])\n",
    "\n",
    "# Create StringIndexer with handleInvalid='keep'\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\", handleInvalid=\"keep\")\n",
    "\n",
    "# Fit the model on training data\n",
    "indexer_model = indexer.fit(data)\n",
    "\n",
    "# Example test data that contains unseen category 'd'\n",
    "test_data = spark.createDataFrame([(\"a\",), (\"b\",), (\"d\",)], [\"category\"])\n",
    "\n",
    "# Transform test data\n",
    "indexed_data = indexer_model.transform(test_data)\n",
    "indexed_data.show()\n",
    "```\n",
    "\n",
    "In this example, unseen categories will be assigned to index `0` (or another default value depending on the training data), avoiding errors during transformation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
